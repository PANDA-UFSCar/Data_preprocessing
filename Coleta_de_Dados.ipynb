{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "p-v9Gt3jBomo",
        "DhQnTifMtz8E",
        "50Ohd_OwpOg9",
        "RBmAHQlwzroR",
        "SsOk0nbe0XVa",
        "QMwQuBMq2G1N",
        "O2PlO10l5ODU",
        "G0up-7Fit7VC",
        "87vTQCNeC9cK",
        "zbxwGwusICj6",
        "1ZF9Iy0STB1K",
        "Ok4alzJR4Eii"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "   <img src = \"https://drive.google.com/uc?id=1JCGXq-eLDEqIh-MIeEEs7VLfde6GFP2q\" width = 240/>\n"
      ],
      "metadata": {
        "id": "vbiMxhT9CqL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Controle e Acesso de Dados"
      ],
      "metadata": {
        "id": "zoW6BMr7AkYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Autor\n",
        "\n",
        "João Ricardo Lopes Lovato\n",
        "\n",
        "Grupo de Preparação de Dados\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9delCNwDfPL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introdução\n",
        "A coleta de dados é o primeiro passo crucial em qualquer projeto de análise de dados, pois influencia diretamente a qualidade e confiabilidade dos resultados obtidos. Garantir uma coleta adequada é essencial para evitar conclusões imprecisas ou inválidas. Neste colab, exploraremos diferentes tipos de coleta, os diferentes tipos de dados, além de aprender a utilizar a biblioteca Pandas para coletar e manipular dados de forma eficiente"
      ],
      "metadata": {
        "id": "ZNPzAQ8WBgdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Pré coleta\n"
      ],
      "metadata": {
        "id": "p-v9Gt3jBomo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de começarmos a coleta em si dos dados de um projeto, existem etapas cruciais que garantirão a coleta adequada dos dados para analise.\n",
        "Sem a etapa de pré coleta as chances de uma situação \"garbage in gabage out\" são muito grandes"
      ],
      "metadata": {
        "id": "OIGqyx9k0iXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Definição de problema"
      ],
      "metadata": {
        "id": "DhQnTifMtz8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A definição adequada do problema é um passo fundamental no processo de coleta de dados na ciência de dados. Antes de iniciar qualquer projeto de análise, é essencial compreender claramente qual é o problema a ser solucionado ou a pergunta a ser respondida por meio dos dados.\n",
        "\n",
        "A definição de problema envolve uma análise cuidadosa e uma compreensão profunda do contexto e dos objetivos do projeto. É importante identificar as necessidades e os desafios específicos que precisam ser abordados. Isso pode incluir a compreensão dos requisitos dos stakeholders, a identificação de lacunas de conhecimento ou a formulação de uma hipótese a ser testada.\n",
        "\n",
        "Existem varias estratégias que podem ser usadas na definição do problema a ser resolvido atraves da analise de dados, alguns deles são:\n",
        "\n",
        "\n",
        "1.   Revisão de Literatura\n",
        "\n",
        ">Realizar uma revisão cuidadosa da literatura existente na área de interesse pode ajudar a identificar lacunas de conhecimento e problemas ainda nao solucionados, tambem é interessante para saber o que ja foi solucionado e usar esses conhecimentos adquiridos na conceptualização da hipótese do problema\n",
        "\n",
        "2.   Analise de dados preliminar\n",
        "\n",
        ">realizar uma análise exploratória inicial dos dados disponíveis, é uma boa forma de identificar padrões, tendências ou anomalias que podem indicar problemas ou questões importantes. Uma pré vizualização dos dados pode ajudar a remover preconceitos ou achismos na concepção do problema\n",
        "\n",
        "3. Definição de objetivos e metas claras\n",
        "\n",
        "> É essencial ter objetivos e metas claras em mente ao definir o problema. Isso envolve entender o propósito da análise de dados e o que se espera alcançar com os resultados. Tambem é importante ter em mente o escopo do projeto. Ao nao levar em consideração o escopo corremos o risco de definir um problema muito amplo e vago, resultando em datasets grandes demais e muito trabalho na hora de minera-los.\n",
        "\n",
        "Vale reforçar que essas são apenas algumas das varias estratégias empregadas na definição de um problema na ciência de dados.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kHMzrtbbB4-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Fontes de dados"
      ],
      "metadata": {
        "id": "50Ohd_OwpOg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o problema definido partimos para o proximo passo, identificar as fontes de dados para análise. Isso pode incluir fontes internas, como bancos de dados da organização, ou fontes externas, como dados públicos ou de terceiros. É importante mais uma vez se atentar ao escopo do projeto, para determinar quais fontes sao realmente necessarias.\n",
        "\n",
        "Ademais nesse momento devemos definir qual tipo de dados serão coletados.\n",
        "\n",
        "1. Dados Primarios\n",
        ">São os dados coletados diretamente pelo pesquisador, esses dados são obtidos por meio de métodos como entrevistas, questionários, observações diretas, experimentos controlados ou coleta de amostras, esses dados possuem melhor adaptabilidade para atender os objetivos da pesquisa, porem sua coleta pode ser demorada e custosa\n",
        "2. Dados Secundários\n",
        ">São os datos ja coletados por outras entidades, empresas privadas ou instituições públicas por exemplo, esses dados podem ser encontrados em fontes como bancos de dados públicos, relatórios governamentais, pesquisas acadêmicas, livros, artigos, dados históricos, entre outros. Apesar de terem a chance de nao se adequarem exatamente ao projeto, necessitando de uma limpeza mais demorada, os dados secundarios possuem a vantagem de ja estarem coletados e disponiveis para uso.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BUoryt7MuFYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Desenvolvimento de instrumentos de coleta de dados\n",
        "\n"
      ],
      "metadata": {
        "id": "RBmAHQlwzroR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crie os instrumentos necessários para coletar os dados de acordo com as técnicas selecionadas. Isso pode envolver a criação de questionários, formulários de observação ou protocolos de entrevista. Certifique-se de que os instrumentos sejam claros, coerentes e adequados para o objetivo do estudo."
      ],
      "metadata": {
        "id": "5VLovtsrz11V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Coleta"
      ],
      "metadata": {
        "id": "SsOk0nbe0XVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o plano de coleta agora concretizado, a proxima etapa é a coleta em si dos dados relevantes ao problema. Existem varios metodos de coleta que podem ser aplicadas como acessos a bancos de dados, APIs, web scrapping entre varios outros. Contudo, todos metodos possuem vantagens e desvantagens, portanto deve-se escolher a estratégia mais adequada ao objetivo do projeto e seu escopo"
      ],
      "metadata": {
        "id": "al7h5xaJ0ba6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 web Scrapping\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QMwQuBMq2G1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web scraping é o processo de extração de dados de uma página da web específica. Isso envolve fazer uma solicitação HTTP ao servidor do site, baixar o HTML da página e analisá-lo para extrair os dados desejados.\n",
        "\n",
        "O web scraping é usado para uma variedade de propósitos, incluindo:\n",
        "\n",
        "Rastreamento e indexação de sites para mecanismos de busca.\n",
        "\n",
        "Coleta de dados para pesquisa de mercado ou análise de concorrentes.\n",
        "\n",
        "Preenchimento de feeds de notícias.\n",
        "\n",
        "Extração de dados para treinar modelos de aprendizado de máquina.\n",
        "\n",
        "O web scraping pode ser feito manualmente, mas se o processo envolver um grande número de páginas da web, é mais eficiente usar uma ferramenta automatizada de web scraping, como BeautifulSoup ou Scrapy.\n",
        "\n",
        "Nessa seção usaremos a biblioteca beaultifulSoup para exemplificar uma coleta atraves de scraping"
      ],
      "metadata": {
        "id": "VfORRNZrssdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1\n",
        "\n"
      ],
      "metadata": {
        "id": "O2PlO10l5ODU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primerio passo é instalar o modolo beaultifulsoup4\n",
        "\n",
        "```\n",
        "$python -m pip install beautifulsoup4\n",
        "```\n",
        "a biblioteca requests é usada para realizar a requição da página ao servidor\n",
        "\n",
        "```python\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "```\n",
        "\n",
        "Devemos entao realizar uma requisão que ficará salva em um objeto do tipo requests"
      ],
      "metadata": {
        "id": "7ErVD6zms4f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "web_url = \"https://pt.wikipedia.org/wiki/Lista_de_bairros_de_Manaus\"\n",
        "\n",
        "data = requests.get(web_url)\n"
      ],
      "metadata": {
        "id": "Xb1EMSyDOGha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "usamos a variavel **web_url** para guardar a url do site que desejamos fazer a coleta, depois usamos request.get(link) para fazer a requisição ao servidor.\n",
        "Se a requisição ocorreu sem problemas, recebemos a mensagem 200 sinalizando o OK"
      ],
      "metadata": {
        "id": "SKvsCAgEPeV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "ymIk18nSQGEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1479f9e3-154d-4a52-9c86-524081e3b30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora com os dados brutos coletados criamos um objeto do tipo BeautifulSoup para extrair os dados dejesados"
      ],
      "metadata": {
        "id": "EFnlpT1FQg9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beautiful_soup = BeautifulSoup(data.content, 'html.parser')\n",
        "print(beautiful_soup.prettify())"
      ],
      "metadata": {
        "id": "pP3RN3GpQs5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora preciamos separar os dados que queremos do documento HTML"
      ],
      "metadata": {
        "id": "PKG6nMNPRIOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('classe de todas as tabelas:')\n",
        "for table in beautiful_soup.find_all('table'):\n",
        "  print(table.get('class'))"
      ],
      "metadata": {
        "id": "nru1X7cMVZx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67551331-dc59-4c75-89f6-b97f44ee08f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classe de todas as tabelas:\n",
            "['box-Desatualizado', 'plainlinks', 'metadata', 'ambox', 'ambox-content']\n",
            "['wikitable', 'sortable']\n",
            "['nowraplinks', 'collapsible', 'collapsed', 'navbox-inner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O codigo acima nos informa todas as classes que cada tabela possui, estamos atras da tabela\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "['wikitable', 'sortable']\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "50bxqf612Lti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tables = beautiful_soup.find_all('table')\n",
        "table = beautiful_soup.find('table', class_='wikitable sortable')"
      ],
      "metadata": {
        "id": "iQUBJodQVc30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a tabela especifica  extraida, agora é questão de inserir os dados em um objeto do tipo DataFrame"
      ],
      "metadata": {
        "id": "7Sm9goME27cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['Neighborhood', 'Zone', 'Area',\n",
        "\t\t\t\t\t\t 'Population', 'Density', 'Homes_count'])\n",
        "\n",
        "mylist = []\n",
        "for table_row in table.tbody.find_all('tr'):\n",
        "  table_columns = table_row.find_all('td')\n",
        "\n",
        "  if(table_columns != []):\n",
        "    neighbor = table_columns[0].text.strip()\n",
        "    zone = table_columns[1].text.strip()\n",
        "    area = table_columns[2].span.contents[0].strip('&0.')\n",
        "    population = table_columns[3].span.contents[0].strip('&0.')\n",
        "    density = table_columns[4].span.contents[0].strip('&0.')\n",
        "    home_count = table_columns[5].span.contents[0].strip('&0.')\n",
        "    mylist.append([neighbor, zone, area, population, density, home_count])\n",
        "\n",
        "df = pd.DataFrame(mylist,\n",
        "   columns=['bairro', 'Zona', 'Area', 'Populacao', 'Densidade', 'numero_de_casas'])\n",
        "\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "QAWDiYn1Vh_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 API"
      ],
      "metadata": {
        "id": "G0up-7Fit7VC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coleta de dados em APIs (Application Programming Interfaces) usando Python é uma prática fundamental para acessar informações e interagir com diversos serviços online. APIs são conjuntos de regras e protocolos que permitem a comunicação e troca de dados entre diferentes sistemas e aplicativos. Ademais, a coleta por meio de APIs tem a vantagem de ja estar formatada e ser facilmente manipulada, os dados geralmente são passados nos formatos  JSON, XML, RSS, Arquivos CSV, entre outros."
      ],
      "metadata": {
        "id": "fcoa1R9Df5Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1"
      ],
      "metadata": {
        "id": "5zjvCDqN3n8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Python oferece uma variedade de bibliotecas, como o requests, que simplificam o processo de envio de solicitações HTTP, recebimento de respostas e manipulação dos dados obtidos. Com a conexão estabelecida, é possível extrair e processar os dados relevantes, permitindo uma ampla gama de aplicações e análises baseadas em dados de APIs, vamos explorar isso usando a biblioteca\n",
        "\n",
        "```python\n",
        "import requests\n",
        "```\n",
        "para realizar a coleta no site thedogapi.com\n",
        "\n"
      ],
      "metadata": {
        "id": "fpqGmntXFulU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = \"https://api.thedogapi.com/v1/breeds/\"\n",
        "\n",
        "response = requests.get(endpoint)\n",
        "\n",
        "response.json()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p4mChhScgW7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar nossa colete teve sucesso e obtvemos todas as raças da api, porem e se quisermos dados especificos ou uma quantidade determinada de raças? Para isso usamos o segundo argumento do metodo .get, os queryparameters, eles nos possibilitam fazer requisições especificas a API, como por exemplo receber apenas as 3 primeiras raças da lista, ou so as raças que tem \"husky\" no nome por exemplo. Os queryparameters são geralmente encontrados na documentação de cada API, a que estamos utilizando tem o parametro de busca definido como\n",
        "\n",
        "```python\n",
        "queryparam = {\"q\" : \"string de busca\"}\n",
        "```\n",
        "Esse parametro funciona para pesquisas apenas por nome da raça\n",
        "\n"
      ],
      "metadata": {
        "id": "9MeBhGCVfUMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_params = {\"q\": \"husky\"}\n",
        "endpoint = \"https://api.thedogapi.com/v1/breeds/search\"\n",
        "obj =  requests.get(endpoint, query_params)\n",
        "obj.json()"
      ],
      "metadata": {
        "id": "Zu-drtmhkh9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tambem podemos usar o parametro limit, para definir quantas raças devem ser retornadas"
      ],
      "metadata": {
        "id": "hpqIJFpfV-EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_params = {\"limit\": \"10\"}\n",
        "endpoint = \"https://api.thedogapi.com/v1/breeds/\"\n",
        "obj =  requests.get(endpoint, query_params)\n",
        "obj.json()"
      ],
      "metadata": {
        "id": "Q256zSBXIgHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com isso dito, nosso objetivo principal é converter os dados dessa requição em um objeto dataframe, a boa noticia é que um objeto do tipo json funciona como um \"dicionario\" tendo seus atributos bem definidos e formatados, assim basta criarmos nosso dataframe e passar o objeto json como argumento\n"
      ],
      "metadata": {
        "id": "_NetPO6xWGR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "url = \"https://api.thedogapi.com/v1/breeds/\"\n",
        "\n",
        "data = requests.get(url)\n",
        "\n",
        "data = data.json()\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#retirando alguns dados para melhorar a vizualização\n",
        "df = df.drop('country_code', axis = 1)\n",
        "\n",
        "df = df.drop('description', axis = 1)\n",
        "\n",
        "df = df.drop('reference_image_id', axis = 1)\n",
        "\n",
        "df = df.drop('image', axis = 1)\n",
        "\n",
        "df = df.drop('history', axis = 1)\n",
        "\n",
        "\n",
        "display(df.head())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u8raiKH2YYdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com os dados propriamente inseridos nossa coleta esta completa e podemos começar a realizar o proximos passos de pre processamento de dados."
      ],
      "metadata": {
        "id": "pS-qBrh6Ep70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Banco de dados\n",
        "\n"
      ],
      "metadata": {
        "id": "jEl9i-pkI2NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geralmente se estamo coletando dados de um banco de dados, especialmente online, o fazemos por meio de uma api, como foi mostrado na sessão anterior.\n",
        "Todavia, existem cenarios em que uma api não estará disponivel para facil acesso aos dados, nesses casos devemos utilizar outras ferramentas para a extração de dados"
      ],
      "metadata": {
        "id": "Cn2MpXA6-usz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1"
      ],
      "metadata": {
        "id": "DXHimO_jATit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro passo é instalar o modulo pymysql"
      ],
      "metadata": {
        "id": "g8G8b3q0Aft1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymysql"
      ],
      "metadata": {
        "id": "U3UzakUoLOLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa291d6-1d00-45bb-8049-20044d66e15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o modulo instalado poderemos importar a biblioteca necessaria para coleta.\n",
        "\n",
        "O primeiro passo é realizar a conexão com o banco de dados alvo\n",
        "\n",
        "```python\n",
        "import pymysql\n",
        "\n",
        "conn = pymysql.connect(\n",
        "    host='localhost',\n",
        "    user='root',\n",
        "    password='password',\n",
        "    db='mydatabase',\n",
        "    charset='utf8mb4',\n",
        "    cursorclass=pymysql.cursors.DictCursor\n",
        ")\n",
        "```\n",
        "para realizar a conexão precisamos dos seguintes argumento:\n",
        "\n",
        "*   host: o nome do host ou endereço IP do servidor MySQL\n",
        "*   user: o nome de usuário usado para autenticação com o servidor MySQL\n",
        "*   password: a senha usada para autenticação com o servidor MySQL\n",
        "*   db: o nome do banco de dados para se conectar\n",
        "*   charset: o conjunto de caracteres a ser usado para a conexão\n",
        "*   cursorclass: o tipo de cursor a ser usado para a conexão (neste caso,usamos o cursor DictCursor, que retorna as linhas como dicionários)\n",
        "\n",
        "Com a conexão feita com sucesso, podemos realizar comandos SQL, assim podendo realizar varias ações na base de dados. Vale lembrar que provavelmente teremos acesso apenas de \"read only\" no banco, podendo apenas vizualizar os dados e nao alterar-los.\n",
        "\n",
        "Para ler dados de um banco de dados SQL usando Python, precisamos executar um comando SELECT do SQL. No exemplo a seguir, vamos ler dados de um banco de dados MySQL e imprimir os resultados:\n",
        "\n",
        "\n",
        "```python\n",
        "try:\n",
        "    with conn.cursor() as cursor:\n",
        "        # Ler dados do banco de dados\n",
        "        sql = \"SELECT * FROM `users`\"\n",
        "        cursor.execute(sql)\n",
        "\n",
        "        # Buscar todas as linhas\n",
        "        rows = cursor.fetchall()\n",
        "\n",
        "        # Imprimir resultados\n",
        "        for row in rows:\n",
        "            print(row)\n",
        "finally:\n",
        "    conn.close()\n",
        "\n",
        "```\n",
        "No código acima, usamos um bloco try/finally para garantir que a conexão com o banco de dados seja fechada corretamente. Dentro do bloco try, usamos a função cursor() para criar um novo objeto de cursor. Em seguida, executamos o comando SELECT usando a função execute().\n",
        "\n",
        "Depois que a função execute() for chamada, usamos a função fetchall() para recuperar todas as linhas retornadas pela consulta. Em seguida, percorremos as linhas e imprimimos os resultados.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qLkkWvMDAn0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Manipulação de formatos de dados"
      ],
      "metadata": {
        "id": "87vTQCNeC9cK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao coletar dados de várias fontes, nos deparamos com o desafio da diversidade de formatos que podemos encontrar na área de ciência de dados e como lidar com essa variedade de arquivos e suas diferentes formas de formatação. Nessa sessão veremos alguns exemplos comuns de arquivos encontrados no momento da coleta.\n",
        "Alguns dos tipos mais comuns de arquivos encontrados sao:\n",
        "\n",
        "* CSV /Text Files /JSON\n",
        "* Microsoft Excel File/ SAS / SQL\n",
        "* Python Pickle File / Stata / HDF5\n",
        "* HTML / ZIP / PDF\n",
        "* DOCX / Images / Google Bigquery\n",
        "\n",
        "Felizmente a biblioteca pandas possui varios metodos que ajudarão na leitura desses arquivos"
      ],
      "metadata": {
        "id": "8UrqfbiZDk_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1 Arquivos CSV"
      ],
      "metadata": {
        "id": "zbxwGwusICj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV é a sigla para \"comma separated values\", um formato de arquivo baseado em texto que armazena dados de forma tabular, semelhante a uma planilha ou tabela de banco de dados. Nesse formato, os valores são separados por vírgulas e os arquivos geralmente possuem a extensão .csv. Quando aberto com o Notepad, um arquivo CSV é exibido como uma sequência de linhas e colunas, permitindo a visualização e manipulação dos dados de forma legível."
      ],
      "metadata": {
        "id": "OlEqJM_wo10c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "req = requests.get(\"https://www1.ncdc.noaa.gov/pub/data/cdo/samples/PRECIP_HLY_sample_csv.csv\")\n",
        "data = req.content\n",
        "csv_file = open('downloaded.csv', 'wb')\n",
        "csv_file.write(data)\n",
        "path = \"/content/downloaded.csv\"\n",
        "csv_data = pd.read_csv(path)\n",
        "display(csv_data)\n",
        "csv_file.close()"
      ],
      "metadata": {
        "id": "-q_6vqzyNbQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Arquivos Excel"
      ],
      "metadata": {
        "id": "1ZF9Iy0STB1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Microsoft Excel é uma planilha desenvolvida pela Microsoft. Às vezes, você pode encontrar dois formatos de arquivo diferentes para o Excel. O primeiro é o XLS, que é uma extensão para a versão do Excel anterior a 2007, enquanto o XLSX é o que você vê atualmente, criado a partir da versão do Excel 2007 em diante. A diferença importante entre as duas extensões de arquivo é que o XLS é um formato binário, enquanto o XLSX é um formato Open XML.\n",
        "\n",
        "Aqui está um código que mostra como você pode importar um arquivo .xlsx."
      ],
      "metadata": {
        "id": "76iGa3wgzLRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "filename = \"/content/sample_data/Financial Sample.xlsx\"\n",
        "df = pd.read_excel(filename)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "Pt93wya5zoaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Aquivos Stata"
      ],
      "metadata": {
        "id": "Ok4alzJR4Eii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stata é uma combinação das palavras \"Statistics\" (estatísticas) + \"data\" (dados) e é amplamente utilizado na área acadêmica de ciências sociais e pesquisa"
      ],
      "metadata": {
        "id": "18_y2azy4Kfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "filename =\"/content/sample_data/airline.dta\"\n",
        "data = pd.read_stata(filename)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "70wFbhI24MNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão\n"
      ],
      "metadata": {
        "id": "Fhz05amMCy8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse colab vimos a importancia da pré coleta de dados e como ela pode influenciar nos resultados do projeto. Ademais, vimos tambem alguma ferramentas que podem ser utilizadas para coletar dados de diferentes fontes, tambem vimos quais o tipos comuns de arquivos encontrados e exemplos de como manipula-los"
      ],
      "metadata": {
        "id": "X2799eUf5LJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencias"
      ],
      "metadata": {
        "id": "nWOeVK5_9XLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "[Raspagem de dados de tabelas HTML com Pandas](https://www.youtube.com/watch?v=0YX0_GZeQwU)<sup>[2.1.1] </sup>\n",
        "\n",
        "[medium](https://deallen7.medium.com/how-to-create-a-pandas-dataframe-from-an-api-endpoint-in-a-jupyter-notebook-f2561f766ca3)<sup>[2.2.1] </sup>\n",
        "\n",
        "\n",
        "[How to Read and Write Data to a SQL Database Using Python](https://www.freecodecamp.org/news/how-to-read-and-write-data-to-a-sql-database-using-python/)<sup>[2.3.1]</sup>\n",
        "\n",
        "[Reading 15 most common file formats used in Data Science](https://www.weirdgeek.com/2018/12/common-file-formats-used-in-data-science/)<sup>[3]</sup>"
      ],
      "metadata": {
        "id": "Bmstc0qzyETS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprofundamento\n",
        "\n"
      ],
      "metadata": {
        "id": "TUSq7NcA53xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[What Is Data Collection: Methods, Types, Tools, and Techniques](https://www.simplilearn.com/what-is-data-collection-article)\n",
        "\n",
        "[Web Scraping with Python - Beautiful Soup Crash Course](https://www.youtube.com/watch?v=XVv6mJpFOb0&t=25s)\n",
        "\n",
        "[Web Scraping com Python](https://www.youtube.com/watch?v=42sTntMEn6o&list=PLg3ZPsW_sghSkRacynznQeEs-vminyTQk)\n",
        "\n",
        "[Consumindo dados da API do YOUTUBE com Python](https://www.youtube.com/watch?v=olDCJ1w3FLM)\n",
        "\n",
        "[Python e APIs: conhecendo a biblioteca Requests](https://www.alura.com.br/conteudo/python-apis-conhecendo-biblioteca-requests?gclid=Cj0KCQjw8NilBhDOARIsAHzpbLAWKnPfodIh6JkI_fT1VgGze1yf3kxbIbDLGF-Bw3YJLAL98MfDQOEaApfWEALw_wcB)"
      ],
      "metadata": {
        "id": "j7KnH1zk6DUh"
      }
    }
  ]
}